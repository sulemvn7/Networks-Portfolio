{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4a801f3-80a2-4a18-aad7-34b750d4a151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: imports and helper\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "def hash_file(path: Path, method: str = \"sha256\", chunk_size: int = 8192) -> str:\n",
    "    \"\"\"\n",
    "    Return hex digest of file at `path` using `method` ('md5' or 'sha256').\n",
    "    Reads in chunks to support large files.\n",
    "    \"\"\"\n",
    "    method = method.lower()\n",
    "    if method == \"md5\":\n",
    "        hasher = hashlib.md5()\n",
    "    elif method in (\"sha256\", \"sha-256\", \"sha_256\"):\n",
    "        hasher = hashlib.sha256()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported hash method. Use 'md5' or 'sha256'.\")\n",
    "\n",
    "    with path.open(\"rb\") as f:\n",
    "        while True:\n",
    "            chunk = f.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            hasher.update(chunk)\n",
    "    return hasher.hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "333a360d-1d99-4517-a8be-0c974d7776ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: create baseline and load/save\n",
    "def create_baseline(root_dir: str, baseline_path: str, hash_method: str = \"sha256\") -> Dict[str, Dict]:\n",
    "    \"\"\"\n",
    "    Walk `root_dir` and create a baseline mapping of relative_path -> {hash, mtime, size}.\n",
    "    Saves baseline as JSON at baseline_path and also returns the dict.\n",
    "    \"\"\"\n",
    "    root = Path(root_dir).resolve()\n",
    "    baseline = {}\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if p.is_file():\n",
    "            rel = str(p.relative_to(root))\n",
    "            file_hash = hash_file(p, method=hash_method)\n",
    "            baseline[rel] = {\n",
    "                \"hash\": file_hash,\n",
    "                \"mtime\": p.stat().st_mtime,\n",
    "                \"size\": p.stat().st_size\n",
    "            }\n",
    "    # Save to JSON\n",
    "    with open(baseline_path, \"w\") as f:\n",
    "        json.dump({\n",
    "            \"root\": str(root),\n",
    "            \"hash_method\": hash_method,\n",
    "            \"generated_at\": time.time(),\n",
    "            \"files\": baseline\n",
    "        }, f, indent=2)\n",
    "    print(f\"‚úÖ Baseline created for '{root}' ({len(baseline)} files) -> '{baseline_path}'\")\n",
    "    return baseline\n",
    "\n",
    "def load_baseline(baseline_path: str) -> Tuple[Path, str, Dict[str, Dict]]:\n",
    "    \"\"\"\n",
    "    Load baseline JSON and return (root_path, hash_method, files_dict).\n",
    "    \"\"\"\n",
    "    with open(baseline_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    root = Path(data[\"root\"])\n",
    "    return root, data[\"hash_method\"], data[\"files\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8405170a-8245-432b-8f2e-4ee498ea3fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: detection function\n",
    "def detect_changes(baseline_path: str, verbose: bool = True) -> Dict[str, list]:\n",
    "    \"\"\"\n",
    "    Compare current filesystem under baseline root to the baseline JSON.\n",
    "    Returns a dict with lists: added, deleted, modified, unchanged.\n",
    "    \"\"\"\n",
    "    root, method, baseline_files = load_baseline(baseline_path)\n",
    "    root = root.resolve()\n",
    "\n",
    "    current_files = {}\n",
    "    for p in root.rglob(\"*\"):\n",
    "        if p.is_file():\n",
    "            rel = str(p.relative_to(root))\n",
    "            current_files[rel] = {\n",
    "                \"hash\": hash_file(p, method=method),\n",
    "                \"mtime\": p.stat().st_mtime,\n",
    "                \"size\": p.stat().st_size\n",
    "            }\n",
    "\n",
    "    baseline_set = set(baseline_files.keys())\n",
    "    current_set = set(current_files.keys())\n",
    "\n",
    "    added = sorted(list(current_set - baseline_set))\n",
    "    deleted = sorted(list(baseline_set - current_set))\n",
    "    possibly_modified = baseline_set & current_set\n",
    "\n",
    "    modified = []\n",
    "    unchanged = []\n",
    "\n",
    "    for rel in sorted(possibly_modified):\n",
    "        if baseline_files[rel][\"hash\"] != current_files[rel][\"hash\"]:\n",
    "            modified.append(rel)\n",
    "        else:\n",
    "            unchanged.append(rel)\n",
    "\n",
    "    report = {\n",
    "        \"added\": added,\n",
    "        \"deleted\": deleted,\n",
    "        \"modified\": modified,\n",
    "        \"unchanged\": unchanged,\n",
    "        \"summary\": {\n",
    "            \"baseline_files\": len(baseline_files),\n",
    "            \"current_files\": len(current_files),\n",
    "            \"added\": len(added),\n",
    "            \"deleted\": len(deleted),\n",
    "            \"modified\": len(modified),\n",
    "            \"unchanged\": len(unchanged)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(\"üîç File Integrity Check Report\")\n",
    "        print(\"=\" * 40)\n",
    "        s = report[\"summary\"]\n",
    "        print(f\"Baseline files: {s['baseline_files']}  |  Current files: {s['current_files']}\")\n",
    "        print(f\"Added: {s['added']}  |  Deleted: {s['deleted']}  |  Modified: {s['modified']}\")\n",
    "        print(\"-\" * 40)\n",
    "        if added:\n",
    "            print(\"‚ûï Added files:\")\n",
    "            for f in added: print(\"   \", f)\n",
    "        if deleted:\n",
    "            print(\"‚ùå Deleted files:\")\n",
    "            for f in deleted: print(\"   \", f)\n",
    "        if modified:\n",
    "            print(\"‚ö†Ô∏è Modified files:\")\n",
    "            for f in modified:\n",
    "                print(\"   \", f)\n",
    "                b = baseline_files[f]\n",
    "                c = current_files[f]\n",
    "                print(f\"      baseline hash: {b['hash']}\")\n",
    "                print(f\"      current  hash: {c['hash']}\")\n",
    "        if not (added or deleted or modified):\n",
    "            print(\"‚úÖ No changes detected (files unchanged).\")\n",
    "        print(\"=\" * 40)\n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd183b0e-a42c-43ae-8808-5403be47335d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Baseline created for 'C:\\Users\\awans\\integrity_demo' (4 files) -> 'baseline_demo.json'\n",
      "üîç File Integrity Check Report\n",
      "========================================\n",
      "Baseline files: 4  |  Current files: 4\n",
      "Added: 1  |  Deleted: 1  |  Modified: 1\n",
      "----------------------------------------\n",
      "‚ûï Added files:\n",
      "    suspicious.txt\n",
      "‚ùå Deleted files:\n",
      "    config\\settings.ini\n",
      "‚ö†Ô∏è Modified files:\n",
      "    lib\\module.py\n",
      "      baseline hash: 2d543015627a771436b30ea79fd0ecda8df8bcd77b3d55661caf5a0d6e809886\n",
      "      current  hash: 8d37da138367eeeb83c76cfca6262dfbfcf2e598cc4466d070ef0078e6202a59\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: demonstration (safe small workspace in notebook)\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "demo_root = Path(\"integrity_demo\")\n",
    "# Clean start\n",
    "if demo_root.exists():\n",
    "    shutil.rmtree(demo_root)\n",
    "demo_root.mkdir()\n",
    "\n",
    "# Create sample files\n",
    "files = {\n",
    "    \"bin/run.exe\": b\"original binary content v1\",\n",
    "    \"lib/module.py\": b\"print('hello world')\\n\",\n",
    "    \"config/settings.ini\": b\"[DEFAULT]\\nsetting=1\\n\",\n",
    "    \"readme.txt\": b\"This is a demo for integrity checking.\\n\"\n",
    "}\n",
    "\n",
    "# Write files\n",
    "for rel, content in files.items():\n",
    "    p = demo_root / rel\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    p.write_bytes(content)\n",
    "\n",
    "# Create baseline\n",
    "baseline_file = \"baseline_demo.json\"\n",
    "create_baseline(str(demo_root), baseline_file, hash_method=\"sha256\")\n",
    "\n",
    "# Simulate tampering:\n",
    "#  - modify lib/module.py\n",
    "#  - delete config/settings.ini\n",
    "#  - add new file suspicious.txt\n",
    "(mod := (demo_root / \"lib\" / \"module.py\")).write_text(\"print('pwned by malware')\\n\")\n",
    "(demo_root / \"config\" / \"settings.ini\").unlink()  # delete\n",
    "(demo_root / \"suspicious.txt\").write_text(\"malicious changes here\\n\")\n",
    "\n",
    "# Run detection\n",
    "report = detect_changes(baseline_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63501228-a1e6-400a-bfdb-3b43b273667a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
